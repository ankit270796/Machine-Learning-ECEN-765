{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "frNHz-osTBn3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Downloading the Database ###\n",
        "#url = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
        "#r = requests.get(url, allow_redirects=True)\n",
        "#open('ml-100k.zip', 'wb').write(r.content)\n",
        "\n",
        "\n",
        "#opener, mode = tarfile.open, 'r:zip'\n",
        "#cwd = os.getcwd()\n",
        "\n",
        "#file=opener('cifar-10-python.tar.gz', mode)\n",
        "#file.extractall()\n",
        "#file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQiSEI0gAziW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### imports ###\n",
        "###############\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from random import randint \n",
        "from scipy.stats import pearsonr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ruqSCcx5A7P2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Funtions ###\n",
        "def readUserDataset(FilePath):\n",
        "  head=['UserId','ItemId','Rating','Timestamp']\n",
        "  return pd.read_csv(FilePath, sep='\\t', names=head)\n",
        "\n",
        "def NumUsers(Dataset):\n",
        "  return Dataset.UserId.unique().shape[0]\n",
        "\n",
        "def NumMovies(MovieDataset):\n",
        "  return MovieDataset.ItemId.unique().shape[0]\n",
        "\n",
        "def CreateUserItemMat(NumUsers,NumItems,Dataset):\n",
        "  matrix=np.zeros((NumUsers, NumItems))\n",
        "  for rating in Dataset.itertuples():\n",
        "    \n",
        "    matrix[rating[1]-1,rating[2]-1]=rating[3]    ### storing a rating corresponding to a user\n",
        "  return matrix\n",
        "\n",
        "def PearsonCorrelation(UserItemMatrix):\n",
        "  similarity=1-pairwise_distances(UserItemMatrix, metric='correlation')\n",
        "  \n",
        "  similarity[np.isnan(similarity)]=0\n",
        "  return similarity\n",
        "\n",
        "def CalculateSimilarity(test, train, num_test, num_train):\n",
        "  similarity=np.zeros((num_test,num_train))\n",
        "  \n",
        "  for i in range(0,num_test):\n",
        "    for j in range(0,num_train):\n",
        "      [p,r]=pearsonr(test[i,:],train[j,:])\n",
        "      similarity[i,j]=p \n",
        "      similarity[np.isnan(similarity)] = 0\n",
        "      \n",
        "  return similarity\n",
        "\n",
        "def InitialRecRandom(test_ratings,num_movies,num_movies_rate):\n",
        "  #### ratings given by the user to presented movies ####\n",
        "  final=np.zeros(test_ratings.shape)\n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    \n",
        "    random_rec=random.sample(range(0, num_movies), num_movies_rate)\n",
        "    for j in random_rec:\n",
        "      final[i,j]=test_ratings[i,j]\n",
        "  \n",
        "  return final\n",
        "  \n",
        "\n",
        "def Predict(train_ratings, test_ratings, similarity, k):  ### predicts with no bias term\n",
        "  pred = np.zeros(test_ratings.shape)\n",
        "  test_user_bias= test_ratings.mean(axis=1)\n",
        "  train_user_bias= train_ratings.mean(axis=1)\n",
        "  \n",
        "  train_ratings=(train_ratings-train_user_bias[:,np.newaxis]).copy()\n",
        "  \n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    \n",
        "    KTopUsers=[np.argsort(similarity[:,i])[:-k-1:-1]]\n",
        "    \n",
        "    for j in range(test_ratings.shape[1]):\n",
        "      pred[i,j]=similarity[i,:][KTopUsers].dot(train_ratings[:,j][KTopUsers])\n",
        "      pred[i,j]/=np.sum(np.abs(similarity[i,:][KTopUsers]))\n",
        "      \n",
        "  pred+= test_user_bias[:,np.newaxis]\n",
        "  return pred\n",
        "\n",
        "\n",
        "#### supporting functions for the demographics #####\n",
        "def ReadDemography(path):  \n",
        "    with zipfile.ZipFile(path) as datafile:  \n",
        "      return datafile.read('ml-100k/u.user').decode(errors='ignore').split('\\n') \n",
        "    \n",
        "def CreateMetadeta(rawDemo, users_age, users_occup,users_meta_data):\n",
        "  for user in rawDemo:\n",
        "    if not user: \n",
        "      continue\n",
        "      \n",
        "    splt=user.split('|')\n",
        "    userid=int(splt[0])\n",
        "    age = int(splt[1])\n",
        "    gender = splt[2]\n",
        "    occup = splt[3] \n",
        "    \n",
        "    i=0\n",
        "    for m in users_age:\n",
        "      if(age <= int(m)):\n",
        "        break ##user belongs to this group\n",
        "      else:\n",
        "        i=i+1\n",
        "    \n",
        "    if(gender=='M'):\n",
        "      j=8\n",
        "    else:\n",
        "      j=9\n",
        "    \n",
        "    k=10\n",
        "    for temp in users_occup:\n",
        "      if(occup==temp):\n",
        "        temp\n",
        "      else:\n",
        "        k=k+1\n",
        "        \n",
        "    s= str(userid)+\"|\"\n",
        "    for l in range (0,31):\n",
        "      if(l==i or l==j or l==k):\n",
        "        s=s+\"1|\"\n",
        "      else:\n",
        "        s=s+\"0|\"\n",
        "        \n",
        "    s=s[:-1]\n",
        "    users_meta_data.append(s)\n",
        "    \n",
        "  return users_meta_data \n",
        "    \n",
        "def DemMatrix(users_meta,num_users):\n",
        "  dem_matrix=np.zeros((num_users,30))\n",
        "  i=0\n",
        "  \n",
        "  for user in users_meta:\n",
        "    splt=user.split('|')\n",
        "    \n",
        "    for j in range (1,31):\n",
        "      dem_matrix[i,j-1]=int(splt[j])\n",
        "    i=i+1\n",
        "    \n",
        "  return dem_matrix\n",
        "\n",
        "def InitialRec(train_ratings, test_ratings, similarity, k, num_movies_rate): #### demographic similarity\n",
        "  pred = np.zeros(test_ratings.shape)\n",
        "  #test_user_bias= test_ratings.mean(axis=1)\n",
        "  #train_user_bias= train_ratings.mean(axis=1)\n",
        "  #train_ratings=(train_ratings-train_user_bias[:,np.newaxis]).copy()\n",
        "  \n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    \n",
        "    KTopUsers=[np.argsort(similarity[:,i])[:-k-1:-1]]\n",
        "    for j in range(test_ratings.shape[1]):\n",
        "      \n",
        "      pred[i,j]=similarity[i,:][KTopUsers].dot(train_ratings[:,j][KTopUsers])\n",
        "      pred[i,j]/=np.sum(np.abs(similarity[i,:][KTopUsers]))\n",
        "  #pred+= test_user_bias[:,np.newaxis]\n",
        "  \n",
        "  #### ratings given by the user to presented movies ####\n",
        "  final=np.zeros(test_ratings.shape)\n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    topKrec=[np.argsort(pred[:,i])[:-num_movies_rate-1:-1]]\n",
        "    \n",
        "    for j in topKrec:\n",
        "      final[i,j]=test_ratings[i,j]\n",
        "      \n",
        "  final[np.isnan(final)] = 0\n",
        "  return final\n",
        "\n",
        "def CalcRMSE(V1,V2):\n",
        "  temp=0\n",
        "  V1[np.isnan(V1)] = 0\n",
        "  V2[np.isnan(V2)] =0\n",
        "  \n",
        "  for i in range(0,V1.shape[0]):\n",
        "    for j in range(0,V1.shape[1]):\n",
        "      temp=temp+pow(V1[i,j]-V2[i,j],2)\n",
        "      \n",
        "  temp=temp/(V1.shape[0]*V1.shape[1])\n",
        "  rmse=pow(temp,1/2)\n",
        "  return rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v7rROazYBQsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "35369c5b-2659-4cba-b7d7-eb9ab74fe9d2"
      },
      "cell_type": "code",
      "source": [
        "##### Basic Part #####\n",
        "#### reading the dataset #######\n",
        "Dataset=readUserDataset(\"u.data\")\n",
        "\n",
        "#UserDataset.tail()  \n",
        "#UserDataset.head()  \n",
        "\n",
        "num_users=NumUsers(Dataset)\n",
        "num_movies=NumMovies(Dataset)\n",
        "\n",
        "#### creating the user item matrix ####\n",
        "user_item_mat=CreateUserItemMat(num_users,num_movies,Dataset)\n",
        "\n",
        "#### Splitting the dataset into 80:20 training vs test dataset ####\n",
        "num_test_users=round(0.2*num_users)\n",
        "num_train_users=num_users-num_test_users\n",
        "\n",
        "\n",
        "\n",
        "k=[10,50,100,150] ###### Neighborhood size\n",
        "movie_set_size=[50,100,150] ##### Number of Movies shown to the user\n",
        "#### to store the result #####\n",
        "basic_result=np.zeros((4,3))\n",
        "\n",
        "i=0\n",
        "for group_size in k:\n",
        "  j=0\n",
        "  for num_movies2rate in movie_set_size:\n",
        "    temp_rmse=0\n",
        "    \n",
        "    for iter in range(0,8):\n",
        "      seperator=random.sample(range(0, num_users), num_users)\n",
        "      \n",
        "      #### grouping the users into test and training sets\n",
        "      test_users=array(seperator[:num_test_users])\n",
        "      train_users=array(seperator[num_test_users:])\n",
        "      \n",
        "      #### creating test and train user item matrix ####\n",
        "      test_user_item=user_item_mat[test_users,:]\n",
        "      train_user_item=user_item_mat[train_users,:]\n",
        "      \n",
        "      ##### creating similarity matrix #####\n",
        "      similarity=CalculateSimilarity(test_user_item, train_user_item, int(num_test_users), int(num_train_users))\n",
        "      \n",
        "      ##### Initial set of movies for ask2rate approach\n",
        "      ask2rate=InitialRecRandom(test_user_item, num_movies, num_movies2rate)\n",
        "      \n",
        "      ##### calculating the predictions #####\n",
        "      predictions=Predict(train_user_item, ask2rate, similarity, group_size)\n",
        "      temp_rmse=temp_rmse + CalcRMSE(predictions,test_user_item)/8\n",
        "      \n",
        "    print(\"Group size: {0}, No of Movies to rate: {1} RMSE: {2}\".format(group_size,num_movies2rate,temp_rmse))  \n",
        "    basic_result[i,j]=temp_rmse\n",
        "    \n",
        "    j=j+1\n",
        "  i=i+1\n",
        "    \n",
        "    \n",
        "print(basic_result)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Group size: 10, No of Movies to rate: 50 RMSE: 0.8795822088084725\n",
            "Group size: 10, No of Movies to rate: 100 RMSE: 0.8991372819445016\n",
            "Group size: 10, No of Movies to rate: 150 RMSE: 0.905258010759722\n",
            "Group size: 50, No of Movies to rate: 50 RMSE: 0.8291862706922684\n",
            "Group size: 50, No of Movies to rate: 100 RMSE: 0.8147145779448272\n",
            "Group size: 50, No of Movies to rate: 150 RMSE: 0.8040799381010442\n",
            "Group size: 100, No of Movies to rate: 50 RMSE: 0.872424794223569\n",
            "Group size: 100, No of Movies to rate: 100 RMSE: 0.8312837871294055\n",
            "Group size: 100, No of Movies to rate: 150 RMSE: 0.8415101398494582\n",
            "Group size: 150, No of Movies to rate: 50 RMSE: 0.8269602960871429\n",
            "Group size: 150, No of Movies to rate: 100 RMSE: 0.8064836411851432\n",
            "Group size: 150, No of Movies to rate: 150 RMSE: 0.8265639558683157\n",
            "[[0.87958221 0.89913728 0.90525801]\n",
            " [0.82918627 0.81471458 0.80407994]\n",
            " [0.87242479 0.83128379 0.84151014]\n",
            " [0.8269603  0.80648364 0.82656396]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "se85lHQXpugJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "avCVM33CnGHK",
        "colab_type": "code",
        "outputId": "37c96076-a736-4f48-e5c3-de3c4df683c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "##### Demography Based #####\n",
        "demography=ReadDemography(\"ml-100k.zip\")\n",
        "\n",
        "#### reading the dataset #######\n",
        "Dataset=readUserDataset(\"u.data\")\n",
        "\n",
        "Dataset.tail()  \n",
        "Dataset.head()  \n",
        "\n",
        "num_users=NumUsers(Dataset)\n",
        "num_movies=NumMovies(Dataset)\n",
        "\n",
        "\n",
        "\n",
        "##### create metadata for the demographics #####\n",
        "users_age = ['18', '24', '30', '40', '50', '61', '70', '100'] \n",
        "users_occup = ['administrator', 'artist', 'doctor', 'educator', 'engineer', 'entertainer', 'executive', 'healthcare', 'homemaker','lawyer', 'librarian', 'marketing', 'none', 'other', 'programmer', 'retired', 'salesman', 'scientist', 'student', 'technician', 'writer']\n",
        "users_combined_features = ['18|0', '24|1', '30|2', '40|3', '50|4', '61|5', '70|6', '100|7', 'm|8', 'f|9', 'administrator|10', 'artist|11', 'doctor|12', 'educator|13', 'engineer|14', 'entertainer|15', 'executive|16', 'healthcare|17', 'homemaker|18', 'lawyer|19', 'librarian|20', 'marketing|21', 'none|22', 'other|23', 'programmer|24', 'retired|25', 'salesman|26', 'scientist|27', 'student|28', 'technician|29', 'writer|30'] \n",
        "\n",
        "users_meta=[]\n",
        "users_meta = CreateMetadeta(demography,users_age,users_occup, users_meta)\n",
        "\n",
        "DemVectors=DemMatrix(users_meta,num_users)\n",
        "\n",
        "#print(DemVectors[354,:])\n",
        "\n",
        "#### creating the user item matrix ####\n",
        "user_item_mat=CreateUserItemMat(num_users,num_movies,Dataset)\n",
        "\n",
        "#### Splitting the dataset into 80:20 training vs test dataset ####\n",
        "num_test_users=round(0.2*num_users)\n",
        "num_train_users=num_users-num_test_users\n",
        "\n",
        "\n",
        "#### to store the result #####\n",
        "dem_result=np.zeros((4,3))\n",
        "\n",
        "i=0\n",
        "for group_size in k:\n",
        "  j=0\n",
        "  for num_movies2rate in movie_set_size:\n",
        "    temp_rmse=0\n",
        "    for iter in range(0,8):\n",
        "      \n",
        "      seperator=random.sample(range(0, num_users), num_users)\n",
        "      \n",
        "      #### grouping the users into test and training sets\n",
        "      test_users=array(seperator[:num_test_users])\n",
        "      train_users=array(seperator[num_test_users:])\n",
        "      \n",
        "      #### creating test and train user item matrix ####\n",
        "      test_user_item=user_item_mat[test_users,:]\n",
        "      train_user_item=user_item_mat[train_users,:]\n",
        "      \n",
        "      #### dividing demographic data ####\n",
        "      test_dem=DemVectors[test_users,:]\n",
        "      train_dem=DemVectors[train_users,:]\n",
        "      \n",
        "      #### Calculating the demographic similarity ####\n",
        "      DemSim=CalculateSimilarity(test_dem, train_dem, int(num_test_users), int(num_train_users))\n",
        "      \n",
        "      k=group_size #users considered.\n",
        "      movies2rate=num_movies2rate\n",
        "      \n",
        "      #### Asked to rate based rating from user ####\n",
        "      ask2ratings=InitialRec(train_user_item, test_user_item, DemSim, k, movies2rate) \n",
        "      \n",
        "      #### Collaborative filtering ####\n",
        "      similarity=CalculateSimilarity(ask2ratings, train_user_item, int(num_test_users), int(num_train_users))\n",
        "      FinalRecommendation=Predict(train_user_item, ask2ratings, similarity, k)\n",
        "      \n",
        "      temp_rmse=temp_rmse + CalcRMSE(FinalRecommendation,test_user_item)/8\n",
        "      \n",
        "    print(\"Group size: {0}, No of Movies to rate: {1} RMSE: {2}\".format(group_size,num_movies2rate,temp_rmse))  \n",
        "    basic_result[i,j]=temp_rmse\n",
        "    \n",
        "    j=j+1\n",
        "  i=i+1\n",
        "  \n",
        "print(basic_result)\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  r = r_num / r_den\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Group size: 10, No of Movies to rate: 50 RMSE: 0.9021540714156902\n",
            "Group size: 10, No of Movies to rate: 100 RMSE: 0.9256455183014564\n",
            "Group size: 10, No of Movies to rate: 150 RMSE: 0.957563229228921\n",
            "Group size: 50, No of Movies to rate: 50 RMSE: 0.821160711666403\n",
            "Group size: 50, No of Movies to rate: 100 RMSE: 0.884445007937726\n",
            "Group size: 50, No of Movies to rate: 150 RMSE: 0.8807421229109011\n",
            "Group size: 100, No of Movies to rate: 50 RMSE: 0.8324862851802002\n",
            "Group size: 100, No of Movies to rate: 100 RMSE: 0.8468091081860127\n",
            "Group size: 100, No of Movies to rate: 150 RMSE: 0.827711337031544\n",
            "Group size: 150, No of Movies to rate: 50 RMSE: 0.85137841184363\n",
            "Group size: 150, No of Movies to rate: 100 RMSE: 0.7847156498282071\n",
            "Group size: 150, No of Movies to rate: 150 RMSE: 0.8088794570957063\n",
            "[[0.90215407 0.92564552 0.95756323]\n",
            " [0.82116071 0.88444501 0.88074212]\n",
            " [0.83248629 0.84680911 0.82771134]\n",
            " [0.85137841 0.78471565 0.80887946]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TvSkovA87sJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}