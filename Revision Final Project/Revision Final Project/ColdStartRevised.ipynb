{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "amcjkL2FoHRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### imports ###\n",
        "###############\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import zipfile\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from numpy import array\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from random import randint \n",
        "from scipy.stats import pearsonr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqoGV5XtoIF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Funtions ###\n",
        "def readUserDataset(FilePath):\n",
        "  head=['UserId','ItemId','Rating','Timestamp']\n",
        "  return pd.read_csv(FilePath, sep='\\t', names=head)\n",
        "\n",
        "def NumUsers(Dataset):\n",
        "  return Dataset.UserId.unique().shape[0]\n",
        "\n",
        "def NumMovies(MovieDataset):\n",
        "  return MovieDataset.ItemId.unique().shape[0]\n",
        "\n",
        "def CreateUserItemMat(NumUsers,NumItems,Dataset):\n",
        "  matrix=np.zeros((NumUsers, NumItems))\n",
        "  for rating in Dataset.itertuples():\n",
        "    \n",
        "    matrix[rating[1]-1,rating[2]-1]=rating[3]    ### storing a rating corresponding to a user\n",
        "  return matrix\n",
        "\n",
        "def PearsonCorrelation(UserItemMatrix):\n",
        "  similarity=1-pairwise_distances(UserItemMatrix, metric='correlation')\n",
        "  \n",
        "  similarity[np.isnan(similarity)]=0\n",
        "  return similarity\n",
        "\n",
        "def CalculateSimilarity(test, train, num_test, num_train):\n",
        "  similarity=np.zeros((num_test,num_train))\n",
        "  \n",
        "  for i in range(0,num_test):\n",
        "    for j in range(0,num_train):\n",
        "      [p,r]=pearsonr(test[i,:],train[j,:])\n",
        "      similarity[i,j]=p \n",
        "      similarity[np.isnan(similarity)] = 0\n",
        "      \n",
        "  return similarity\n",
        "\n",
        "def InitialRecRandom(test_ratings,num_movies,num_movies_rate):\n",
        "  #### ratings given by the user to presented movies ####\n",
        "  final=np.zeros(test_ratings.shape)\n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    \n",
        "    random_rec=random.sample(range(0, num_movies), num_movies_rate)\n",
        "    for j in random_rec:\n",
        "      final[i,j]=test_ratings[i,j]\n",
        "  \n",
        "  return final\n",
        "  \n",
        "\n",
        "def Predict(train_ratings, test_ratings, similarity, k):  ### predicts with no bias term\n",
        "  pred = np.zeros(test_ratings.shape)\n",
        "  test_user_bias= test_ratings.mean(axis=1)\n",
        "  train_user_bias= train_ratings.mean(axis=1)\n",
        "  \n",
        "  train_ratings=(train_ratings-train_user_bias[:,np.newaxis]).copy()\n",
        "  \n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    \n",
        "    KTopUsers=[np.argsort(similarity[:,i])[:-k-1:-1]]\n",
        "    \n",
        "    for j in range(test_ratings.shape[1]):\n",
        "      pred[i,j]=similarity[i,:][KTopUsers].dot(train_ratings[:,j][KTopUsers])\n",
        "      pred[i,j]/=np.sum(np.abs(similarity[i,:][KTopUsers]))\n",
        "      \n",
        "  pred+= test_user_bias[:,np.newaxis]\n",
        "  return pred\n",
        "\n",
        "def plot_comparison(x1,x2,x3,Kvector,name):\n",
        "  \n",
        "    fig = plt.figure()\n",
        "    for j in range(0,x1.shape[0]):\n",
        "      lab=\"K=\"+str(Kvector[j])\n",
        "      plt.plot(Kvector, x1[j,:], label=lab)\n",
        "      \n",
        "    plt.xlabel('neighborhood size')\n",
        "    plt.ylabel('hitrate')\n",
        "    plt.title(name[0])\n",
        "    plt.legend()\n",
        "\n",
        "    \n",
        "    fig = plt.figure()\n",
        "    for j in range(0,x2.shape[0]):\n",
        "      lab=\"K=\"+str(Kvector[j])\n",
        "      plt.plot(Kvector, x2[j,:], label=lab)\n",
        "      \n",
        "    plt.xlabel('neighborhood size')\n",
        "    plt.ylabel('hitrate')\n",
        "    plt.title(name[1])\n",
        "    plt.legend()\n",
        "\n",
        "    fig = plt.figure()\n",
        "    for j in range(0,x3.shape[0]):\n",
        "      lab=\"K=\"+str(Kvector[j])\n",
        "      plt.plot(Kvector, x3[j,:], label=lab)\n",
        "      \n",
        "    plt.xlabel('neighborhood size')\n",
        "    plt.ylabel('hitrate')\n",
        "    plt.title(name[2])  \n",
        "    plt.legend()\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.plot(Kvector, x1[0,:], label=name[0])\n",
        "    plt.plot(Kvector, x2[0,:], label=name[1])\n",
        "    plt.plot(Kvector, x3[0,:], label=name[2])\n",
        "    plt.xlabel('neighborhood size')\n",
        "    plt.ylabel('hitrate')\n",
        "    plt.title('Comparison for K=10')  \n",
        "    plt.legend()\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.plot(Kvector, x1[1,:], label=name[0])\n",
        "    plt.plot(Kvector, x2[1,:], label=name[1])\n",
        "    plt.plot(Kvector, x3[1,:], label=name[2])\n",
        "    plt.xlabel('neighborhood size')\n",
        "    plt.ylabel('hitrate')\n",
        "    plt.title('Comparison for K=50')  \n",
        "    plt.legend()\n",
        "\n",
        "#### supporting functions for the demographics #####\n",
        "def ReadDemography(path):  \n",
        "    with zipfile.ZipFile(path) as datafile:  \n",
        "      return datafile.read('ml-100k/u.user').decode(errors='ignore').split('\\n') \n",
        "    \n",
        "def CreateMetadeta(rawDemo, users_age, users_occup,users_meta_data):\n",
        "  for user in rawDemo:\n",
        "    if not user: \n",
        "      continue\n",
        "      \n",
        "    splt=user.split('|')\n",
        "    userid=int(splt[0])\n",
        "    age = int(splt[1])\n",
        "    gender = splt[2]\n",
        "    occup = splt[3] \n",
        "    \n",
        "    i=0\n",
        "    for m in users_age:\n",
        "      if(age <= int(m)):\n",
        "        break ##user belongs to this group\n",
        "      else:\n",
        "        i=i+1\n",
        "    \n",
        "    if(gender=='M'):\n",
        "      j=8\n",
        "    else:\n",
        "      j=9\n",
        "    \n",
        "    k=10\n",
        "    for temp in users_occup:\n",
        "      if(occup==temp):\n",
        "        temp\n",
        "      else:\n",
        "        k=k+1\n",
        "        \n",
        "    s= str(userid)+\"|\"\n",
        "    for l in range (0,31):\n",
        "      if(l==i or l==j or l==k):\n",
        "        s=s+\"1|\"\n",
        "      else:\n",
        "        s=s+\"0|\"\n",
        "        \n",
        "    s=s[:-1]\n",
        "    users_meta_data.append(s)\n",
        "    \n",
        "  return users_meta_data \n",
        "    \n",
        "def DemMatrix(users_meta,num_users):\n",
        "  dem_matrix=np.zeros((num_users,30))\n",
        "  i=0\n",
        "  \n",
        "  for user in users_meta:\n",
        "    splt=user.split('|')\n",
        "    \n",
        "    for j in range (1,31):\n",
        "      dem_matrix[i,j-1]=int(splt[j])\n",
        "    i=i+1\n",
        "    \n",
        "  return dem_matrix\n",
        "\n",
        "def InitialRec(train_ratings, test_ratings, similarity, k, num_movies_rate): #### demographic similarity\n",
        "  pred = np.zeros(test_ratings.shape)\n",
        "  #test_user_bias= test_ratings.mean(axis=1)\n",
        "  #train_user_bias= train_ratings.mean(axis=1)\n",
        "  #train_ratings=(train_ratings-train_user_bias[:,np.newaxis]).copy()\n",
        "  \n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    \n",
        "    KTopUsers=[np.argsort(similarity[:,i])[:-k-1:-1]]\n",
        "    for j in range(test_ratings.shape[1]):\n",
        "      \n",
        "      pred[i,j]=similarity[i,:][KTopUsers].dot(train_ratings[:,j][KTopUsers])\n",
        "      pred[i,j]/=np.sum(np.abs(similarity[i,:][KTopUsers]))\n",
        "  #pred+= test_user_bias[:,np.newaxis]\n",
        "  \n",
        "  #### ratings given by the user to presented movies ####\n",
        "  final=np.zeros(test_ratings.shape)\n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    topKrec=[np.argsort(pred[:,i])[:-num_movies_rate-1:-1]]\n",
        "    \n",
        "    for j in topKrec:\n",
        "      final[i,j]=test_ratings[i,j]\n",
        "      \n",
        "  final[np.isnan(final)] = 0\n",
        "  return final\n",
        "\n",
        "def CalcRMSE(V1,V2):\n",
        "  temp=0\n",
        "  V1[np.isnan(V1)] = 0\n",
        "  V2[np.isnan(V2)] =0\n",
        "  \n",
        "  for i in range(0,V1.shape[0]):\n",
        "    for j in range(0,V1.shape[1]):\n",
        "      temp=temp+pow(V1[i,j]-V2[i,j],2)\n",
        "      \n",
        "  temp=temp/(V1.shape[0]*V1.shape[1])\n",
        "  rmse=pow(temp,1/2)\n",
        "  return rmse\n",
        "\n",
        "def HitRate(test_ratings, predicted, k):\n",
        "  total_ratings=(test_ratings.shape[0])*k\n",
        "  miss=0\n",
        "  for i in range(test_ratings.shape[0]):\n",
        "    topK=[np.argsort(predicted[i,:])[:-k-1:-1]]\n",
        "    zero_els = np.count_nonzero(test_ratings[i,topK]==0)\n",
        "    miss=miss+zero_els \n",
        "  \n",
        "  hit_rate=1-miss/total_ratings\n",
        "  return hit_rate\n",
        "      \n",
        "num_iter=5   \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmxZfqL3oKtK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Basic Part #####\n",
        "#### reading the dataset #######\n",
        "Dataset=readUserDataset(\"u.data\")\n",
        "\n",
        "#UserDataset.tail()  \n",
        "#UserDataset.head()  \n",
        "\n",
        "num_users=NumUsers(Dataset)\n",
        "num_movies=NumMovies(Dataset)\n",
        "\n",
        "#### creating the user item matrix ####\n",
        "user_item_mat=CreateUserItemMat(num_users,num_movies,Dataset)\n",
        "\n",
        "#### Splitting the dataset into 80:20 training vs test dataset ####\n",
        "num_test_users=round(0.2*num_users)\n",
        "num_train_users=num_users-num_test_users\n",
        "\n",
        "\n",
        "\n",
        "k=[10,50,100,150] ###### Neighborhood size\n",
        "movie_set_size=[15,30,45,60] ##### Number of Movies shown to the user\n",
        "#### to store the result #####\n",
        "basic_result=np.zeros((4,4))\n",
        "hr1=np.zeros((4,4))\n",
        "\n",
        "i=0\n",
        "for group_size in k:\n",
        "  j=0\n",
        "  for num_movies2rate in movie_set_size:\n",
        "    temp_rmse=0\n",
        "    hit_rate=0\n",
        "    for iter in range(0,num_iter):\n",
        "      seperator=random.sample(range(0, num_users), num_users)\n",
        "      \n",
        "      #### grouping the users into test and training sets\n",
        "      test_users=array(seperator[:num_test_users])\n",
        "      train_users=array(seperator[num_test_users:])\n",
        "      \n",
        "      #### creating test and train user item matrix ####\n",
        "      test_user_item=user_item_mat[test_users,:]\n",
        "      train_user_item=user_item_mat[train_users,:]\n",
        "      \n",
        "      ##### Initial set of movies for ask2rate approach\n",
        "      ask2rate=InitialRecRandom(test_user_item, num_movies, num_movies2rate)\n",
        "      \n",
        "      ##### creating similarity matrix #####\n",
        "      similarity=CalculateSimilarity(ask2rate, train_user_item, int(num_test_users), int(num_train_users))\n",
        "      \n",
        "      ##### calculating the predictions #####\n",
        "      predictions=Predict(train_user_item, ask2rate, similarity, group_size)\n",
        "      \n",
        "      #temp_rmse=temp_rmse + CalcRMSE(predictions,test_user_item)\n",
        "      \n",
        "      hit_rate=hit_rate+HitRate(test_user_item, predictions, num_movies2rate)/num_iter\n",
        "    \n",
        "    print(\"Group size: {0}, No of Movies to rate: {1} Hit-Rate: {2}\".format(group_size,num_movies2rate,hit_rate))  \n",
        "    #basic_result[i,j]=temp_rmse\n",
        "    \n",
        "    hr1[i,j]=hit_rate\n",
        "    j=j+1\n",
        "  i=i+1\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJhQbwFloR0F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### Demography Based #####\n",
        "demography=ReadDemography(\"ml-100k.zip\")\n",
        "\n",
        "#### reading the dataset #######\n",
        "Dataset=readUserDataset(\"u.data\")\n",
        "\n",
        "Dataset.tail()  \n",
        "Dataset.head()  \n",
        "\n",
        "num_users=NumUsers(Dataset)\n",
        "num_movies=NumMovies(Dataset)\n",
        "\n",
        "\n",
        "\n",
        "##### create metadata for the demographics #####\n",
        "users_age = ['18', '24', '30', '40', '50', '61', '70', '100'] \n",
        "users_occup = ['administrator', 'artist', 'doctor', 'educator', 'engineer', 'entertainer', 'executive', 'healthcare', 'homemaker','lawyer', 'librarian', 'marketing', 'none', 'other', 'programmer', 'retired', 'salesman', 'scientist', 'student', 'technician', 'writer']\n",
        "users_combined_features = ['18|0', '24|1', '30|2', '40|3', '50|4', '61|5', '70|6', '100|7', 'm|8', 'f|9', 'administrator|10', 'artist|11', 'doctor|12', 'educator|13', 'engineer|14', 'entertainer|15', 'executive|16', 'healthcare|17', 'homemaker|18', 'lawyer|19', 'librarian|20', 'marketing|21', 'none|22', 'other|23', 'programmer|24', 'retired|25', 'salesman|26', 'scientist|27', 'student|28', 'technician|29', 'writer|30'] \n",
        "\n",
        "users_meta=[]\n",
        "users_meta = CreateMetadeta(demography,users_age,users_occup, users_meta)\n",
        "\n",
        "DemVectors=DemMatrix(users_meta,num_users)\n",
        "\n",
        "#print(DemVectors[354,:])\n",
        "\n",
        "#### creating the user item matrix ####\n",
        "user_item_mat=CreateUserItemMat(num_users,num_movies,Dataset)\n",
        "\n",
        "#### Splitting the dataset into 80:20 training vs test dataset ####\n",
        "num_test_users=round(0.2*num_users)\n",
        "num_train_users=num_users-num_test_users\n",
        "\n",
        "k=[10,50,100,150] ###### Neighborhood size\n",
        "movie_set_size=[15,30,45,60] ##### Number of Movies shown to the user\n",
        "\n",
        "#### to store the result #####\n",
        "dem_result=np.zeros((4,4))\n",
        "hr0=np.zeros((4,4))\n",
        "\n",
        "i=0\n",
        "for group_size in k:\n",
        "  j=0\n",
        "  for num_movies2rate in movie_set_size:\n",
        "    temp_rmse=0\n",
        "    \n",
        "    hit_rate=0\n",
        "    for iter in range(0,num_iter):\n",
        "      \n",
        "      seperator=random.sample(range(0, num_users), num_users)\n",
        "      \n",
        "      #### grouping the users into test and training sets\n",
        "      test_users=array(seperator[:num_test_users])\n",
        "      train_users=array(seperator[num_test_users:])\n",
        "      \n",
        "      #### creating test and train user item matrix ####\n",
        "      test_user_item=user_item_mat[test_users,:]\n",
        "      train_user_item=user_item_mat[train_users,:]\n",
        "      \n",
        "      #### dividing demographic data ####\n",
        "      test_dem=DemVectors[test_users,:]\n",
        "      train_dem=DemVectors[train_users,:]\n",
        "      \n",
        "      #### Calculating the demographic similarity ####\n",
        "      DemSim=CalculateSimilarity(test_dem, train_dem, int(num_test_users), int(num_train_users))\n",
        "      \n",
        "      k=group_size #users considered.\n",
        "      movies2rate=num_movies2rate\n",
        "      \n",
        "      #### Asked to rate based rating from user ####\n",
        "      ask2ratings=InitialRec(train_user_item, test_user_item, DemSim, k, movies2rate) \n",
        "      \n",
        "      #### Collaborative filtering ####\n",
        "      similarity=CalculateSimilarity(test_user_item, train_user_item, int(num_test_users), int(num_train_users))\n",
        "      FinalRecommendation=Predict(train_user_item, ask2ratings, similarity, k)\n",
        "      \n",
        "      ##temp_rmse=temp_rmse + CalcRMSE(FinalRecommendation,test_user_item)/8\n",
        "      hit_rate=hit_rate+HitRate(test_user_item, predictions, num_movies2rate)/num_iter\n",
        "    print(\"Group size: {0}, No of Movies to rate: {1} Hit-Rate: {2}\".format(group_size,num_movies2rate,hit_rate))  \n",
        "    #basic_result[i,j]=temp_rmse\n",
        "    hr0[i,j]=hit_rate\n",
        "    \n",
        "    j=j+1\n",
        "  i=i+1\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYfMP3_HoSzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##### based on popularity\n",
        "#### reading the dataset #######\n",
        "Dataset=readUserDataset(\"u.data\")\n",
        "\n",
        "num_users=NumUsers(Dataset)\n",
        "num_movies=NumMovies(Dataset)\n",
        "\n",
        "#### creating the user item matrix ####\n",
        "user_item_mat=CreateUserItemMat(num_users,num_movies,Dataset)\n",
        "user_item_mat_copy=user_item_mat\n",
        "\n",
        "#### most popular movie calculation ####\n",
        "locations=np.where(user_item_mat_copy>0)\n",
        "user_item_mat_copy[locations]=1\n",
        "final_sum=user_item_mat_copy.sum(axis=1)\n",
        "\n",
        "#### Splitting the dataset into 80:20 training vs test dataset ####\n",
        "num_test_users=round(0.2*num_users)\n",
        "num_train_users=num_users-num_test_users\n",
        "\n",
        "k=[10,50,100,150] ###### Neighborhood size\n",
        "movie_set_size=[15,30,45,60] ##### Number of Movies shown to the user\n",
        "#### to store the result #####\n",
        "\n",
        "hr2=np.zeros((4,4))\n",
        "\n",
        "i=0\n",
        "for group_size in k:\n",
        "  j=0\n",
        "  for num_movies2rate in movie_set_size:\n",
        "    temp_rmse=0\n",
        "    hit_rate=0\n",
        "    for iter in range(0,num_iter):\n",
        "      \n",
        "      seperator=random.sample(range(0, num_users), num_users)\n",
        "      \n",
        "      #### grouping the users into test and training sets\n",
        "      test_users=array(seperator[:num_test_users])\n",
        "      train_users=array(seperator[num_test_users:])\n",
        "      \n",
        "      #### creating test and train user item matrix ####\n",
        "      test_user_item=user_item_mat[test_users,:]\n",
        "      train_user_item=user_item_mat[train_users,:]\n",
        "      \n",
        "      k=group_size #users considered.\n",
        "      movies2rate=num_movies2rate\n",
        "      \n",
        "      #### Asked to rate based rating from user based on popularity ####\n",
        "      ask2ratings=np.zeros(test_user_item.shape)\n",
        "      topK=[np.argsort(final_sum)[:-num_movies2rate-1:-1]]\n",
        "     \n",
        "     \n",
        "      for l in range(0,test_user_item.shape[0]):\n",
        "        for m in topK:\n",
        "          ask2ratings[l,m]=test_user_item[l,m]\n",
        "         \n",
        "      \n",
        "      #### Collaborative filtering ####\n",
        "      similarity=CalculateSimilarity(ask2ratings, train_user_item, int(num_test_users), int(num_train_users))\n",
        "      FinalRecommendation=Predict(train_user_item, ask2ratings, similarity, k)\n",
        "      \n",
        "      ##temp_rmse=temp_rmse + CalcRMSE(FinalRecommendation,test_user_item)/8\n",
        "      hit_rate=hit_rate+HitRate(test_user_item, FinalRecommendation, num_movies2rate)/num_iter\n",
        "    \n",
        "    print(\"Group size: {0}, No of Movies to rate: {1} Hit-Rate: {2}\".format(group_size,num_movies2rate,hit_rate))  \n",
        "    #basic_result[i,j]=temp_rmse\n",
        "    hr2[i,j]=hit_rate\n",
        "    \n",
        "    j=j+1\n",
        "  i=i+1\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9k9EUG84oXwh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "K=np.array([10, 50, 100, 150])\n",
        "name=[\"Basic\",\"Demography-based\",\"Popularity-Based\"]\n",
        "plot_comparison(hr1,hr0,hr2,K,name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}